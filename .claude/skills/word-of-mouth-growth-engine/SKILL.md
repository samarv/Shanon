---
name: word-of-mouth-growth-engine
description: A framework to drive organic growth by identifying specific product pillars that trigger customer recommendations and closing the "perception gap" through in-product value visualization. Use this when your unit economics limit paid acquisition, when building in a commodity category, or when aiming for viral-led distribution.
---

# Word-of-Mouth Growth Engine

This framework focuses on moving a product from "functional" to "remarkable" by identifying the core drivers of customer advocacy and ensuring users actually perceive the value you've delivered.

## 1. Map Viral Potential to NPS Thresholds
Standard NPS tracking is insufficient; you must correlate NPS scores with actual referral behavior to find your "evangelism threshold."

*   **Overlay Data:** Match individual NPS survey responses to user referral data (invites sent and conversion rates).
*   **Identify the "Double" Points:** At Wise, moving a user from a 6 to a 7/8 doubled referrals. Moving them from 8 to 9 doubled them again.
*   **Target the 9-10s:** True word-of-mouth growth only happens when you move users into the "socks blown off" category (NPS 9 or 10).

## 2. Identify and Over-Index on Advocacy Pillars
Mining the qualitative comments in your NPS surveys reveals the "Product Pillars" that actually drive recommendations.

*   **Analyze the Comments:** Look for recurring themes in the 9-10 scores. For Wise, these were: **Price, Speed, and Ease of Use.**
*   **Ignore the Noise:** Many things are "important" (e.g., trust, branding), but only a few things drive *advocacy*. Focus engineering resources almost exclusively on these pillars.
*   **Set 10x Goals:** Don't aim for 10% improvements. Ask: "What is the theoretical minimum cost/time for this process?" Work backward from that ideal rather than iterating forward from the status quo.

## 3. Close the Perception Gap
Doing the hard work to make a product better is useless for word-of-mouth if the user doesn't *notice* the improvement.

*   **Product Marketing Within the UI:** Use visual cues to ensure the user feels the value you've created.
*   **Visualize the Comparison:** If you saved the user money, show exactly how much compared to the next best alternative using a graph or table at the moment of success.
*   **Add "Sensation" to Speed:** If a process is now instant, add a high-quality animation or "success" state that emphasizes the speed. If it's too fast, users may not even realize the "hard work" was done.

## 4. Prioritize a Single "Happiness" List
Avoid having two separate roadmaps (one for "Revenue" and one for "Customers").

*   **The Single List:** Maintain one prioritized list of tasks that increase customer happiness (NPS). 
*   **Trust the Flywheel:** Build conviction that if you solve the hardest technical or regulatory problems to improve your core pillars, the resulting word-of-mouth will drive more volume, which creates the revenue to solve even harder problems.

## Examples

**Example 1: Visualizing Savings**
*   **Context:** A user completes an international transfer.
*   **Input:** The system knows the user paid 0.35% while a traditional bank charges 6%.
*   **Application:** Instead of a simple "Success" message, show a comparison graph: "You just saved $42 compared to using Bank X."
*   **Output:** A 3x increase in the sharing/referral rate on the success screen because the value is now concrete, not abstract.

**Example 2: Engineering Away Verification Friction**
*   **Context:** Regulatory requirements in Singapore required face-to-face meetings to verify identity.
*   **Input:** High friction/cost of verification was killing the "Ease of Use" pillar.
*   **Application:** The team did the "unscalable" work of meeting people in person while simultaneously lobbying the government for a year to allow E-KYC (digital verification).
*   **Output:** The first E-KYC license in the region, creating a 10x faster experience than any competitor, which triggered massive organic growth in that market.

## Common Pitfalls

*   **Stopping at "Functional":** Most teams stop when a feature works. Word-of-mouth requires "blowing socks off," which usually happens only after the feature is 10x better than the alternative.
*   **The "Split-Test Only" Trap:** You cannot split-test your way to "love." Some 10x improvements take years of infrastructure work (e.g., getting a central bank account) and won't show a clear ROI in a 2-week A/B test.
*   **Hiding Your Magic:** Assuming users know how hard you worked. If you made something 50% faster, but the UI looks the same, the user perception (and therefore advocacy) won't change.
*   **Generic Pillars:** Choosing pillars like "Quality" or "Brand." Pillars must be specific and measurable (e.g., "Instant Transfers" or "0% Markup").